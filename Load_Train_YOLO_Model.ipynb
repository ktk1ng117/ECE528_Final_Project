{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6e9eb8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6e9eb8d",
        "outputId": "f2829d6c-76c1-482e-8053-3d0684640bc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s-cls.pt to 'yolo11s-cls.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13.0MB 89.6MB/s 0.1s.1s<0.1s\n",
            "YOLO11s-cls summary: 86 layers, 6,724,008 parameters, 0 gradients, 13.2 GFLOPs\n",
            "ClassificationModel(\n",
            "  (model): Sequential(\n",
            "    (0): Conv(\n",
            "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (1): Conv(\n",
            "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (2): C3k2(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (4): C3k2(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (5): Conv(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (6): C3k2(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): C3k(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv3): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (1): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (7): Conv(\n",
            "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (8): C3k2(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): C3k(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv3): Conv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (1): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (9): C2PSA(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): Sequential(\n",
            "        (0): PSABlock(\n",
            "          (attn): Attention(\n",
            "            (qkv): Conv(\n",
            "              (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (act): Identity()\n",
            "            )\n",
            "            (proj): Conv(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (act): Identity()\n",
            "            )\n",
            "            (pe): Conv(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (act): Identity()\n",
            "            )\n",
            "          )\n",
            "          (ffn): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (act): Identity()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (10): Classify(\n",
            "      (conv): Conv(\n",
            "        (conv): Conv2d(512, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (pool): AdaptiveAvgPool2d(output_size=1)\n",
            "      (drop): Dropout(p=0.0, inplace=True)\n",
            "      (linear): Linear(in_features=1280, out_features=1000, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#!pip install ultralytics\n",
        "from ultralytics import YOLO\n",
        "import torch.nn as nn\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import os, time\n",
        "import numpy as np\n",
        "\n",
        "#Replacing the classifier head with one for our dataset\n",
        "model = YOLO(\"yolo11s-cls.pt\")\n",
        "model.info()\n",
        "print(model.model)\n",
        "\n",
        "model.model.model[10].linear = nn.Linear(\n",
        "    in_features=1280,\n",
        "    out_features=8,\n",
        "    bias=True\n",
        ")\n",
        "#Freeze rest of model\n",
        "for name, param in model.model.named_parameters():\n",
        "    param.requires_grad = False\n",
        "#unfreeze classifier head\n",
        "for param in model.model.model[10].linear.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x99vEqAe9-8y",
      "metadata": {
        "id": "x99vEqAe9-8y"
      },
      "outputs": [],
      "source": [
        "zip_path = '/content/greyscale_downsampled_split.zip'\n",
        "extract_path = '/content/greyscale_downsampled_split'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "0a0b98ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a0b98ee",
        "outputId": "3beaf7be-72dd-4277-d47b-d889603a00fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.228 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/greyscale_downsampled_split/greyscale_downsampled_split, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train4, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/classify/train4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/greyscale_downsampled_split/greyscale_downsampled_split/train... found 13823 images in 8 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/greyscale_downsampled_split/greyscale_downsampled_split/val... found 3454 images in 8 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/greyscale_downsampled_split/greyscale_downsampled_split/test... found 4317 images in 8 classes ‚úÖ \n",
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 10                  -1  1    668168  ultralytics.nn.modules.head.Classify         [512, 8]                      \n",
            "YOLO11s-cls summary: 86 layers, 5,453,256 parameters, 5,453,256 gradients, 12.1 GFLOPs\n",
            "Transferred 236/236 items from pretrained weights\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1124.5¬±407.1 MB/s, size: 25.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/greyscale_downsampled_split/greyscale_downsampled_split/train... 13823 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13823/13823 19.8Mit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 371.4¬±72.0 MB/s, size: 29.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/greyscale_downsampled_split/greyscale_downsampled_split/val... 3454 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3454/3454 999.1Kit/s 0.0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
            "Image sizes 224 train, 224 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/classify/train4\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      1/100     0.525G     0.4759         15        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 864/864 22.1it/s 39.1s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 64.8it/s 1.7s\n",
            "                   all      0.857      0.999\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      2/100     0.592G     0.1846         15        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 864/864 26.2it/s 32.9s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 64.1it/s 1.7s\n",
            "                   all      0.779      0.991\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      3/100     0.592G     0.3003         15        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 864/864 26.5it/s 32.7s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 64.8it/s 1.7s\n",
            "                   all      0.673      0.965\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      4/100     0.592G      0.429         15        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 864/864 27.9it/s 31.0s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 62.0it/s 1.7s\n",
            "                   all      0.787      0.992\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      5/100     0.602G     0.3793         15        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 864/864 27.0it/s 32.0s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 63.7it/s 1.7s\n",
            "                   all      0.752      0.977\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      6/100     0.602G     0.3188         15        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 864/864 27.1it/s 31.9s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 64.0it/s 1.7s\n",
            "                   all      0.798      0.991\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 5 epochs. Best results observed at epoch 1, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=5) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "6 epochs completed in 0.059 hours.\n",
            "Optimizer stripped from /content/runs/classify/train4/weights/last.pt, 11.0MB\n",
            "Optimizer stripped from /content/runs/classify/train4/weights/best.pt, 11.0MB\n",
            "\n",
            "Validating /content/runs/classify/train4/weights/best.pt...\n",
            "Ultralytics 8.3.228 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLO11s-cls summary (fused): 47 layers, 5,444,376 parameters, 0 gradients, 12.0 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/greyscale_downsampled_split/greyscale_downsampled_split/train... found 13823 images in 8 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/greyscale_downsampled_split/greyscale_downsampled_split/val... found 3454 images in 8 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/greyscale_downsampled_split/greyscale_downsampled_split/test... found 4317 images in 8 classes ‚úÖ \n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 71.8it/s 1.5s\n",
            "                   all      0.857      0.999\n",
            "Speed: 0.1ms preprocess, 0.3ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/classify/train4\u001b[0m\n",
            "Training time: 218.37 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "results = model.train(data=r\"/content/greyscale_downsampled_split/greyscale_downsampled_split\", epochs=100, patience=5, lr0=0.001, imgsz=224, device=\"cuda:0\")\n",
        "end_time = time.time()\n",
        "training_duration = end_time - start_time\n",
        "print(f\"Training time: {training_duration:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7d99783d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d99783d",
        "outputId": "61085110-f90c-447c-dbd2-b6bba026fb29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.228 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLO11s-cls summary (fused): 47 layers, 5,444,376 parameters, 0 gradients, 12.0 GFLOPs\n",
            "WARNING ‚ö†Ô∏è Dataset 'split=train' not found at /content/greyscale_downsampled_split/greyscale_downsampled_split/test/train\n",
            "Found 4317 images in subdirectories. Attempting to split...\n",
            "Splitting /content/greyscale_downsampled_split/greyscale_downsampled_split/test (8 classes, 4317 images) into 80% train, 20% val...\n",
            "Split complete in /content/greyscale_downsampled_split/greyscale_downsampled_split/test_split ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/greyscale_downsampled_split/greyscale_downsampled_split/test_split/train... found 3489 images in 8 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/greyscale_downsampled_split/greyscale_downsampled_split/test_split/val... found 902 images in 8 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 477.5¬±121.2 MB/s, size: 25.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/greyscale_downsampled_split/greyscale_downsampled_split/test_split/val... 902 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 902/902 3.4Kit/s 0.3s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/greyscale_downsampled_split/greyscale_downsampled_split/test_split/val.cache\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 53.0it/s 1.1s\n",
            "                   all      0.897          1\n",
            "Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/classify/val4\u001b[0m\n",
            "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
            "\n",
            "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x79fd6fe3e7b0>\n",
            "curves: []\n",
            "curves_results: []\n",
            "fitness: 0.9484478831291199\n",
            "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
            "results_dict: {'metrics/accuracy_top1': 0.8968957662582397, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9484478831291199}\n",
            "save_dir: PosixPath('/content/runs/classify/val4')\n",
            "speed: {'preprocess': 0.12599204102068956, 'inference': 0.7855046818193582, 'loss': 0.0008319412415732058, 'postprocess': 0.0012823580934315626}\n",
            "task: 'classify'\n",
            "top1: 0.8968957662582397\n",
            "top5: 1.0\n"
          ]
        }
      ],
      "source": [
        "metrics = model.val(data=r\"/content/greyscale_downsampled_split/greyscale_downsampled_split/test\")\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c07832bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c07832bf",
        "outputId": "b6503785-1018-4f98-bf07-b29280e3cbbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.228 üöÄ Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/runs/classify/train4/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 8) (10.5 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 22...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.74...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 0.8s, saved as '/content/runs/classify/train4/weights/best.onnx' (20.8 MB)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.3...\n",
            "Saved artifact at '/content/runs/classify/train4/weights/best_saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serving_default'\n",
            "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 224, 224, 3), dtype=tf.float32, name='images')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 8), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  134133232150736: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  134133232155536: TensorSpec(shape=(3, 3, 3, 32), dtype=tf.float32, name=None)\n",
            "  134133232153808: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  134133232143632: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  134133232145936: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  134133232146512: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134133232153424: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  134133232152080: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134133232149968: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134133232149008: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134133232156496: TensorSpec(shape=(3, 3, 32, 16), dtype=tf.float32, name=None)\n",
            "  134133232150544: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  134133232150352: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
            "  134133232152656: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  134133232150928: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134133232151312: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134133232147664: TensorSpec(shape=(1, 1, 96, 128), dtype=tf.float32, name=None)\n",
            "  134133232154000: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134133232155728: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  134133232151696: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  134133232149200: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134133232148432: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  134133232156304: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134133232155152: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134133232148048: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134133232148624: TensorSpec(shape=(3, 3, 64, 32), dtype=tf.float32, name=None)\n",
            "  134133232144784: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  134133232154192: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  134133232154576: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134133232146704: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134133232148816: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134133232153040: TensorSpec(shape=(1, 1, 192, 256), dtype=tf.float32, name=None)\n",
            "  134133232144976: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134133232155344: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  134133232146320: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
            "  134133232156112: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134133232144592: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  134133232149776: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134134925220304: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134134925218576: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134136183689040: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  134133232145744: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134134925221072: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134134925223184: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134134925222992: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134134925224336: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134134925219152: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134134925220880: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134134925220496: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134133232149392: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  134134925219728: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134133232143056: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134134925224912: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  134134925220688: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134134925218960: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134134925215312: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134134925222608: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  134134925221264: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134134925224144: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  134134925222416: TensorSpec(shape=(3, 3, 256, 512), dtype=tf.float32, name=None)\n",
            "  134134925223376: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  134134925221456: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
            "  134134925225104: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  134134925222800: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134134925224528: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134134925216272: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  134134925216656: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134134925229136: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  134134925216080: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134134925213776: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  134134925229520: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134134925217232: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  134134925227408: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134134925226256: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  134134925223952: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  134134925221840: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134134925225488: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134134925223760: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  134134925213968: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134134925222224: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134134925225296: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134134925220112: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
            "  134134925217040: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  134134925227984: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
            "  134134925223568: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  134134925215696: TensorSpec(shape=(1, 1, 256, 512), dtype=tf.float32, name=None)\n",
            "  134134925229712: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  134134925214544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134143750765648: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134143750765264: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  134134925219920: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134134925218768: TensorSpec(shape=(1, 1, 256, 512), dtype=tf.float32, name=None)\n",
            "  134134925217808: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  134134925215888: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  134134925219536: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134134925216464: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
            "  134134925219344: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  134133244157520: TensorSpec(shape=(1, 1, 512, 1280), dtype=tf.float32, name=None)\n",
            "  134133244156560: TensorSpec(shape=(1280,), dtype=tf.float32, name=None)\n",
            "  134133244164816: TensorSpec(shape=(1280, 8), dtype=tf.float32, name=None)\n",
            "  134133244158096: TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
            "  134133244155216: TensorSpec(shape=(8,), dtype=tf.float32, name=None)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ‚úÖ 10.2s, saved as '/content/runs/classify/train4/weights/best_saved_model' (52.3 MB)\n",
            "\n",
            "Export complete (10.3s)\n",
            "Results saved to \u001b[1m/content/runs/classify/train4/weights\u001b[0m\n",
            "Predict:         yolo predict task=classify model=/content/runs/classify/train4/weights/best_saved_model imgsz=224  \n",
            "Validate:        yolo val task=classify model=/content/runs/classify/train4/weights/best_saved_model imgsz=224 data=/content/greyscale_downsampled_split/greyscale_downsampled_split  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/runs/classify/train4/weights/best_saved_model'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Grey Model\n",
        "model.export(format=\"saved_model\", keras=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AGjLpdFaSqb5",
      "metadata": {
        "id": "AGjLpdFaSqb5"
      },
      "outputs": [],
      "source": [
        "loaded_model = tf.keras.models.load_model(r\"C:\\Graduate_School\\Fall_2025\\ECE528\\Final_Project\\best_saved_model (1)\")\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "with open('model_yolov11_quantized_grey.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hTEElgfsSuKK",
      "metadata": {
        "id": "hTEElgfsSuKK"
      },
      "outputs": [],
      "source": [
        "loaded_model = tf.keras.models.load_model(r\"C:\\Graduate_School\\Fall_2025\\ECE528\\Final_Project\\best_saved_model (1)\")\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
        "tflite_model = converter.convert()\n",
        "with open('model_yolov11_grey.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PUJyVX-8JH42",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PUJyVX-8JH42",
        "outputId": "b7a4db25-94db-458b-f402-8bb2bfe273f2"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_d855a3ea-e3b1-40c8-b966-1fd34b85e9a7\", \"best_saved_model.zip\", 49367631)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive(\"/content/runs/classify/train4/weights/best_saved_model\", 'zip', \"/content/runs/classify/train4/weights/best_saved_model\")\n",
        "\n",
        "# Download the zip\n",
        "files.download(\"/content/runs/classify/train4/weights/best_saved_model.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "oa9Pc2VjLRS9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oa9Pc2VjLRS9",
        "outputId": "9b053faa-a871-4477-ce58-0000cac4008f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLO11s-cls summary: 86 layers, 6,724,008 parameters, 0 gradients, 13.2 GFLOPs\n",
            "ClassificationModel(\n",
            "  (model): Sequential(\n",
            "    (0): Conv(\n",
            "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (1): Conv(\n",
            "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (2): C3k2(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (4): C3k2(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (5): Conv(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (6): C3k2(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): C3k(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv3): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (1): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (7): Conv(\n",
            "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (8): C3k2(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): C3k(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv3): Conv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (1): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (9): C2PSA(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): Sequential(\n",
            "        (0): PSABlock(\n",
            "          (attn): Attention(\n",
            "            (qkv): Conv(\n",
            "              (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (act): Identity()\n",
            "            )\n",
            "            (proj): Conv(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (act): Identity()\n",
            "            )\n",
            "            (pe): Conv(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (act): Identity()\n",
            "            )\n",
            "          )\n",
            "          (ffn): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (act): Identity()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (10): Classify(\n",
            "      (conv): Conv(\n",
            "        (conv): Conv2d(512, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (pool): AdaptiveAvgPool2d(output_size=1)\n",
            "      (drop): Dropout(p=0.0, inplace=True)\n",
            "      (linear): Linear(in_features=1280, out_features=1000, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = YOLO(\"yolo11s-cls.pt\")\n",
        "model.info()\n",
        "print(model.model)\n",
        "\n",
        "model.model.model[10].linear = nn.Linear(\n",
        "    in_features=1280,\n",
        "    out_features=8,\n",
        "    bias=True\n",
        ")\n",
        "#Freeze rest of model\n",
        "for name, param in model.model.named_parameters():\n",
        "    param.requires_grad = False\n",
        "#unfreeze classifier head\n",
        "for param in model.model.model[10].linear.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DLy6AlNcLmLe",
      "metadata": {
        "id": "DLy6AlNcLmLe"
      },
      "outputs": [],
      "source": [
        "zip_path = '/content/original_downsampled_split.zip'\n",
        "extract_path = '/content/original_downsampled_split'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c921b8d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c921b8d6",
        "outputId": "43e568ac-b4c0-473b-ed16-c7b8c3bc12bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.228 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/original_downsampled_split/original_downsampled_split, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/classify/train3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/original_downsampled_split/original_downsampled_split/train... found 13823 images in 8 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/original_downsampled_split/original_downsampled_split/val... found 3454 images in 8 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/original_downsampled_split/original_downsampled_split/test... found 4317 images in 8 classes ‚úÖ \n",
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 10                  -1  1    668168  ultralytics.nn.modules.head.Classify         [512, 8]                      \n",
            "YOLO11s-cls summary: 86 layers, 5,453,256 parameters, 5,453,256 gradients, 12.1 GFLOPs\n",
            "Transferred 236/236 items from pretrained weights\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1074.0¬±376.1 MB/s, size: 30.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/original_downsampled_split/original_downsampled_split/train... 13823 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13823/13823 3.3Kit/s 4.2s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/original_downsampled_split/original_downsampled_split/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 630.2¬±338.9 MB/s, size: 33.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/original_downsampled_split/original_downsampled_split/val... 3454 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3454/3454 2.9Kit/s 1.2s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/original_downsampled_split/original_downsampled_split/val.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
            "Image sizes 224 train, 224 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/classify/train3\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      1/100     0.543G     0.3766         15        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 864/864 23.2it/s 37.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 64.2it/s 1.7s\n",
            "                   all      0.892      0.999\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      2/100     0.586G     0.1355         15        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 864/864 26.3it/s 32.9s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 65.7it/s 1.6s\n",
            "                   all      0.767      0.991\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      3/100     0.598G      0.269         15        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 864/864 27.4it/s 31.5s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 66.4it/s 1.6s\n",
            "                   all      0.692      0.911\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      4/100     0.607G     0.3972         15        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 864/864 27.6it/s 31.3s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 61.0it/s 1.8s\n",
            "                   all      0.761      0.979\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      5/100     0.619G     0.3447         15        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 864/864 28.1it/s 30.7s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 63.6it/s 1.7s\n",
            "                   all      0.824       0.99\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      6/100     0.654G     0.2962         15        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 864/864 28.3it/s 30.6s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 67.8it/s 1.6s\n",
            "                   all      0.791      0.989\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 5 epochs. Best results observed at epoch 1, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=5) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "6 epochs completed in 0.057 hours.\n",
            "Optimizer stripped from /content/runs/classify/train3/weights/last.pt, 11.0MB\n",
            "Optimizer stripped from /content/runs/classify/train3/weights/best.pt, 11.0MB\n",
            "\n",
            "Validating /content/runs/classify/train3/weights/best.pt...\n",
            "Ultralytics 8.3.228 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLO11s-cls summary (fused): 47 layers, 5,444,376 parameters, 0 gradients, 12.0 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/original_downsampled_split/original_downsampled_split/train... found 13823 images in 8 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/original_downsampled_split/original_downsampled_split/val... found 3454 images in 8 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/original_downsampled_split/original_downsampled_split/test... found 4317 images in 8 classes ‚úÖ \n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 86.3it/s 1.3s\n",
            "                   all      0.892      0.999\n",
            "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/classify/train3\u001b[0m\n",
            "Training time: 217.44 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "#Baseline Results\n",
        "results = model.train(data=r\"/content/original_downsampled_split/original_downsampled_split\", epochs=100, patience=5, lr0=0.001, imgsz=224, device=\"cuda:0\")\n",
        "\n",
        "end_time = time.time()\n",
        "training_duration = end_time - start_time\n",
        "print(f\"Training time: {training_duration:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a8c6d183",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8c6d183",
        "outputId": "beb2f219-c939-41ad-ebb7-02fe4150d90d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.228 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "WARNING ‚ö†Ô∏è Dataset 'split=train' not found at /content/original_downsampled_split/original_downsampled_split/test/train\n",
            "Found 4317 images in subdirectories. Attempting to split...\n",
            "Splitting /content/original_downsampled_split/original_downsampled_split/test (8 classes, 4317 images) into 80% train, 20% val...\n",
            "Split complete in /content/original_downsampled_split/original_downsampled_split/test_split ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/original_downsampled_split/original_downsampled_split/test_split/train... found 3452 images in 8 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/original_downsampled_split/original_downsampled_split/test_split/val... found 865 images in 8 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 860.2¬±305.6 MB/s, size: 29.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/original_downsampled_split/original_downsampled_split/test_split/val... 865 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 865/865 3.0Kit/s 0.3s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/original_downsampled_split/original_downsampled_split/test_split/val.cache\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 55/55 66.9it/s 0.8s\n",
            "                   all      0.897          1\n",
            "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/classify/val3\u001b[0m\n",
            "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
            "\n",
            "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x79fd263e8590>\n",
            "curves: []\n",
            "curves_results: []\n",
            "fitness: 0.9485549032688141\n",
            "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
            "results_dict: {'metrics/accuracy_top1': 0.8971098065376282, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9485549032688141}\n",
            "save_dir: PosixPath('/content/runs/classify/val3')\n",
            "speed: {'preprocess': 0.1253609236981497, 'inference': 0.6369765664742304, 'loss': 0.0007635826580296237, 'postprocess': 0.0011904023128245908}\n",
            "task: 'classify'\n",
            "top1: 0.8971098065376282\n",
            "top5: 1.0\n"
          ]
        }
      ],
      "source": [
        "metrics = model.val(data=r\"/content/original_downsampled_split/original_downsampled_split/test\")\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "f8f44532",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f8f44532",
        "outputId": "5cdc6ffd-e665-407d-cf71-fbd68f2658df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.228 üöÄ Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/runs/classify/train3/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 8) (10.5 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 22...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.74...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 0.8s, saved as '/content/runs/classify/train3/weights/best.onnx' (20.8 MB)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.3...\n",
            "Saved artifact at '/content/runs/classify/train3/weights/best_saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serving_default'\n",
            "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 224, 224, 3), dtype=tf.float32, name='images')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 8), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  134134925218192: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  134134925220304: TensorSpec(shape=(3, 3, 3, 32), dtype=tf.float32, name=None)\n",
            "  134134925217616: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  134134925218576: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  134134925219152: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  134134925216848: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134134925220496: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  134134925221072: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134134925223184: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134134925222992: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134134925224336: TensorSpec(shape=(3, 3, 32, 16), dtype=tf.float32, name=None)\n",
            "  134134925220688: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  134134925220880: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
            "  134134925219728: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  134134925222416: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134134925223376: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134134925224912: TensorSpec(shape=(1, 1, 96, 128), dtype=tf.float32, name=None)\n",
            "  134134925222608: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134134925221264: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  134134925224144: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  134134925223952: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134134925221456: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  134134925225104: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134134925225488: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134134925224528: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134134925222800: TensorSpec(shape=(3, 3, 64, 32), dtype=tf.float32, name=None)\n",
            "  134134925222224: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  134134925225296: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  134134925222032: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134134925224720: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134134925226256: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134134925221648: TensorSpec(shape=(1, 1, 192, 256), dtype=tf.float32, name=None)\n",
            "  134134925229136: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134134925217232: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  134134925227600: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
            "  134134925216272: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134134925216656: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  134134925216080: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134133232147856: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134133232146128: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134134925213776: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  134134925229520: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134133232149008: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134133232152656: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134133232153232: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134133232149968: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134133232149584: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134133232151312: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134133232150352: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134134925213968: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  134133232150928: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134133232150736: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134133232152272: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  134133232146512: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134133232145936: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134133232143632: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134133232154384: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  134133232152080: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134133232154576: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  134133232153424: TensorSpec(shape=(3, 3, 256, 512), dtype=tf.float32, name=None)\n",
            "  134133232154000: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  134133232155536: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
            "  134133232154768: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  134133232152848: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134133232155920: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134133232151696: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  134133232151504: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134133232156496: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  134133232150544: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134133232147664: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  134133232149200: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134133232155728: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  134133232148432: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134133232156304: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  134133232154192: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  134133232148048: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134133232155152: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134133232146704: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  134133232148816: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134133232153616: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134133232154960: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134133232144976: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
            "  134133232145360: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  134133232146320: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
            "  134133232145744: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  134133232143248: TensorSpec(shape=(1, 1, 256, 512), dtype=tf.float32, name=None)\n",
            "  134133232148624: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  134134918200976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134134918195600: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134133232144784: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  134135259375440: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134134918198288: TensorSpec(shape=(1, 1, 256, 512), dtype=tf.float32, name=None)\n",
            "  134134918197904: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  134134918199056: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  134134918200784: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134134918197328: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
            "  134134918200400: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  134134918199248: TensorSpec(shape=(1, 1, 512, 1280), dtype=tf.float32, name=None)\n",
            "  134135266010384: TensorSpec(shape=(1280,), dtype=tf.float32, name=None)\n",
            "  134135266011728: TensorSpec(shape=(1280, 8), dtype=tf.float32, name=None)\n",
            "  134135266011152: TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
            "  134135266009616: TensorSpec(shape=(8,), dtype=tf.float32, name=None)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ‚úÖ 9.2s, saved as '/content/runs/classify/train3/weights/best_saved_model' (52.1 MB)\n",
            "\n",
            "Export complete (9.3s)\n",
            "Results saved to \u001b[1m/content/runs/classify/train3/weights\u001b[0m\n",
            "Predict:         yolo predict task=classify model=/content/runs/classify/train3/weights/best_saved_model imgsz=224  \n",
            "Validate:        yolo val task=classify model=/content/runs/classify/train3/weights/best_saved_model imgsz=224 data=/content/original_downsampled_split/original_downsampled_split  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/runs/classify/train3/weights/best_saved_model'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.export(format=\"saved_model\", keras=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wXPeDFQhLMfa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wXPeDFQhLMfa",
        "outputId": "922031c5-d174-430d-f248-f2e33151f22b"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_93f04515-c897-44bd-b767-d6796a33b006\", \"best_saved_model.zip\", 49339674)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Zip the folder\n",
        "shutil.make_archive(\"/content/runs/classify/train3/weights/best_saved_model\", 'zip', \"/content/runs/classify/train3/weights/best_saved_model\")\n",
        "\n",
        "# Download the zip\n",
        "files.download(\"/content/runs/classify/train3/weights/best_saved_model.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GaAHK0tnF0kY",
      "metadata": {
        "id": "GaAHK0tnF0kY"
      },
      "outputs": [],
      "source": [
        "#YOLOv11 quantized trained on grey images\n",
        "loaded_model = tf.keras.models.load_model(r\"C:\\Graduate_School\\Fall_2025\\ECE528\\Final_Project\\Final_Project_Models\\Create_Models\\YOLOv11\\Grey\\best_saved_model\")\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "with open('model_yolov11_quantized_grey.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i0aRXc-UFuoO",
      "metadata": {
        "id": "i0aRXc-UFuoO"
      },
      "outputs": [],
      "source": [
        "#YOLOv11 trained on grey images\n",
        "loaded_model = tf.keras.models.load_model(r\"C:\\Graduate_School\\Fall_2025\\ECE528\\Final_Project\\Final_Project_Models\\Create_Models\\YOLOv11\\Grey\\best_saved_model\")\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
        "tflite_model = converter.convert()\n",
        "with open('model_yolov11_grey.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_vB_sEIaFu7Z",
      "metadata": {
        "id": "_vB_sEIaFu7Z"
      },
      "outputs": [],
      "source": [
        "#YOLOv11 quantized trained on original images\n",
        "loaded_model = tf.keras.models.load_model(r\"C:\\Graduate_School\\Fall_2025\\ECE528\\Final_Project\\Final_Project_Models\\Create_Models\\YOLOv11\\Original\\best_saved_model\")\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "with open('model_yolov11_quantized_original.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ew-lXGAMFvDM",
      "metadata": {
        "id": "ew-lXGAMFvDM"
      },
      "outputs": [],
      "source": [
        "#YOLOv11 quantized trained on original images\n",
        "loaded_model = tf.keras.models.load_model(r\"C:\\Graduate_School\\Fall_2025\\ECE528\\Final_Project\\Final_Project_Models\\Create_Models\\YOLOv11\\Original\\best_saved_model\")\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
        "tflite_model = converter.convert()\n",
        "with open('model_yolov11_original.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2992a21",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4317 files belonging to 8 classes.\n"
          ]
        }
      ],
      "source": [
        "#Load the test dataset\n",
        "data_dir = r\"C:\\Graduate_School\\Fall_2025\\ECE528\\Final_Project\\Final_Project_Models\\Create_Models\\data\\north_american_predators\\greyscale_downsampled_split\\test\"\n",
        "dataset_test = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  seed=123,\n",
        "  image_size=(224, 224),\n",
        "  batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ffaeeb6",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model_tflite(interpreter, dataset):\n",
        "    #List of dictionaries\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in dataset:\n",
        "        input_type = input_details[0]['dtype']\n",
        "        # Convert the batch to the correct type\n",
        "        images = images.numpy().astype(input_type)\n",
        "        labels = labels.numpy()\n",
        "        \n",
        "        for i in range(images.shape[0]):\n",
        "            test_image = np.expand_dims(images[i], axis=0)\n",
        "            #From Tensorflow API Docs\n",
        "            interpreter.set_tensor(input_details[0]['index'], test_image)\n",
        "            interpreter.invoke()\n",
        "            output = interpreter.get_tensor(output_details[0]['index'])\n",
        "            #Gets the most prominent class\n",
        "            pred = np.argmax(output)\n",
        "            if pred == labels[i]:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2497fb0a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TFLite accuracy: 0.41649293490850126\n",
            "TFlite model in Mb: 20.802791595458984\n"
          ]
        }
      ],
      "source": [
        "#YOLOv11 trained on original images\n",
        "interpreter = tf.lite.Interpreter(model_path=r\"C:\\Graduate_School\\Fall_2025\\ECE528\\Final_Project\\Final_Project_Models\\Create_Models\\YOLOv11\\Original\\model_yolov11_original.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "acc = evaluate_model_tflite(interpreter, dataset_test)        \n",
        "print(\"TFLite accuracy:\", acc)\n",
        "print(\"TFlite model in Mb:\", os.path.getsize(r\"C:\\Graduate_School\\Fall_2025\\ECE528\\Final_Project\\Final_Project_Models\\Create_Models\\YOLOv11\\Original\\model_yolov11_original.tflite\") / float(2**20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c404544e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TFLite accuracy: 0.41649293490850126\n",
            "TFlite model in Mb: 5.356437683105469\n"
          ]
        }
      ],
      "source": [
        "#YOLOv11 quantized trained on original images\n",
        "interpreter = tf.lite.Interpreter(model_path=r\"C:\\Graduate_School\\Fall_2025\\ECE528\\Final_Project\\Final_Project_Models\\Create_Models\\YOLOv11\\Original\\model_yolov11_quantized_original.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "acc = evaluate_model_tflite(interpreter, dataset_test)        \n",
        "print(\"TFLite accuracy:\", acc)\n",
        "print(\"TFlite model in Mb:\", os.path.getsize(r\"C:\\Graduate_School\\Fall_2025\\ECE528\\Final_Project\\Final_Project_Models\\Create_Models\\YOLOv11\\Original\\model_yolov11_quantized_original.tflite\") / float(2**20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9enxV7mbFvK5",
      "metadata": {
        "id": "9enxV7mbFvK5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TFLite accuracy: 0.4157980078758397\n",
            "TFlite model in Mb: 20.803260803222656\n"
          ]
        }
      ],
      "source": [
        "#YOLOv11 trained on grey images\n",
        "interpreter = tf.lite.Interpreter(model_path=r\"C:\\Graduate_School\\Fall_2025\\ECE528\\Final_Project\\Final_Project_Models\\Create_Models\\YOLOv11\\Grey\\model_yolov11_grey.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "acc = evaluate_model_tflite(interpreter, dataset_test)        \n",
        "print(\"TFLite accuracy:\", acc)\n",
        "print(\"TFlite model in Mb:\", os.path.getsize(r\"C:\\Graduate_School\\Fall_2025\\ECE528\\Final_Project\\Final_Project_Models\\Create_Models\\YOLOv11\\Grey\\model_yolov11_grey.tflite\") / float(2**20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d67abb5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TFLite accuracy: 0.41649293490850126\n",
            "TFlite model in Mb: 5.356903076171875\n"
          ]
        }
      ],
      "source": [
        "#YOLOv11 quantized trained on grey images\n",
        "interpreter = tf.lite.Interpreter(model_path=r\"C:\\Graduate_School\\Fall_2025\\ECE528\\Final_Project\\Final_Project_Models\\Create_Models\\YOLOv11\\Grey\\model_yolov11_quantized_grey.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "acc = evaluate_model_tflite(interpreter, dataset_test)        \n",
        "print(\"TFLite accuracy:\", acc)\n",
        "print(\"TFlite model in Mb:\", os.path.getsize(r\"C:\\Graduate_School\\Fall_2025\\ECE528\\Final_Project\\Final_Project_Models\\Create_Models\\YOLOv11\\Grey\\model_yolov11_quantized_grey.tflite\") / float(2**20))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
